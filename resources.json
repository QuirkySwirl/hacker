[
  {
    "id": "9091-principle-1-rule",
    "title": "90–9–1 Principle (1% Rule)",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<p>The 90-9-1 principle suggests that within an internet community such as a wiki, 90% of participants only consume content, 9% edit or modify content and 1% of participants add content.</p>\n<ul>\n<li>A 2014 study of four digital health social networks found the top 1% created 73% of posts, the next 9% accounted for an average of ~25% and the remaining 90% accounted for an average of 2% (<a href=\"https://www.jmir.org/2014/2/e33/\">Reference</a>)</li>\n</ul>\n<ul>\n<li><a href=\"#the-pareto-principle-the-8020-rule\">Pareto principle</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=90%E2%80%939%E2%80%931+Principle+(1%25+Rule)",
    "sourceUrl": "https://en.wikipedia.org/wiki/1%25_rule_(Internet_culture)",
    "seeAlso": []
  },
  {
    "id": "9090-rule",
    "title": "90–90 Rule",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>The first 90 percent of the code accounts for the first 90 percent of the development time. The remaining 10 percent of the code accounts for the other 90 percent of the development time.</p>\n</blockquote>\n<p>A wry reinterpretation of the <a href=\"#the-pareto-principle-the-8020-rule\">Pareto Principe (or 80-20 rule)</a> that highlights the real-world challenges of completing engineering work. This sentiment is also echoed in <a href=\"#hofstadters-law\">Hofstadter&#39;s Law</a>.</p>\n<ul>\n<li><a href=\"#hofstadters-law\">Hofstadter&#39;s Law</a></li>\n<li><a href=\"#the-pareto-principle-the-8020-rule\">The Pareto Principe</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=90%E2%80%9390+Rule",
    "sourceUrl": "https://en.wikipedia.org/wiki/Ninety%E2%80%93ninety_rule",
    "seeAlso": []
  },
  {
    "id": "amdahls-law",
    "title": "Amdahl's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>Amdahl&#39;s Law is a formula which shows the <em>potential speedup</em> of a computational task which can be achieved by increasing the resources of a system. Normally used in parallel computing, it can predict the actual benefit of increasing the number of processors, which is limited by the parallelisability of the program.</p>\n</blockquote>\n<p>Best illustrated with an example. If a program is made up of two parts, part A, which must be executed by a single processor, and part B, which can be parallelised, then we see that adding multiple processors to the system executing the program can only have a limited benefit. It can potentially greatly improve the speed of part B - but the speed of part A will remain unchanged.</p>\n<p>The diagram below shows some examples of potential improvements in speed:</p>\n<img width=\"480px\" alt=\"Diagram: Amdahl's Law\" src=\"./images/amdahls_law.png\" />\n\n<p><em>(Image Reference: By Daniels219 at English Wikipedia, Creative Commons Attribution-Share Alike 3.0 Unported, <a href=\"https://en.wikipedia.org/wiki/File:AmdahlsLaw.svg\">https://en.wikipedia.org/wiki/File:AmdahlsLaw.svg</a>)</em></p>\n<p>As can be seen, even a program which is 50% parallelisable will benefit very little beyond 10 processing units, whereas a program which is 95% parallelisable can still achieve significant speed improvements with over a thousand processing units.</p>\n<p>As <a href=\"#moores-law\">Moore&#39;s Law</a> slows, and the acceleration of individual processor speed slows, parallelisation is key to improving performance. Graphics programming is an excellent example - with modern Shader based computing, individual pixels or fragments can be rendered in parallel - this is why modern graphics cards often have many thousands of processing cores (GPUs or Shader Units).</p>\n<ul>\n<li><a href=\"#brooks-law\">Brooks&#39; Law</a></li>\n<li><a href=\"#moores-law\">Moore&#39;s Law</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Amdahl's+Law",
    "sourceUrl": "https://en.wikipedia.org/wiki/Amdahl%27s_law",
    "seeAlso": []
  },
  {
    "id": "the-broken-windows-theory",
    "title": "The Broken Windows Theory",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<p>The Broken Windows Theory suggests that visible signs of crime (or lack of care of an environment) lead to further and more serious crimes (or further deterioration of the environment).</p>\n<p>This theory has been applied to software development, suggesting that poor quality code (or <a href=\"#TODO\">Technical Debt</a>) can lead to a perception that efforts to improve quality may be ignored or undervalued, thus leading to further poor quality code. This effect cascades leading to a great decrease in quality over time.</p>\n<ul>\n<li><a href=\"#TODO\">Technical Debt</a></li>\n</ul>\n<p>Examples:</p>\n<ul>\n<li><a href=\"https://flylib.com/books/en/1.315.1.15/1/\">The Pragmatic Programming: Software Entropy</a></li>\n<li><a href=\"https://blog.codinghorror.com/the-broken-window-theory/\">Coding Horror: The Broken Window Theory</a></li>\n<li><a href=\"https://opensourceforu.com/2011/05/joy-of-programming-broken-window-theory/\">OpenSource: Joy of Programming - The Broken Window Theory</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Broken+Windows+Theory",
    "sourceUrl": "https://en.wikipedia.org/wiki/Broken_windows_theory",
    "seeAlso": []
  },
  {
    "id": "brooks-law",
    "title": "Brooks' Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>Adding human resources to a late software development project makes it later.</p>\n</blockquote>\n<p>This law suggests that in many cases, attempting to accelerate the delivery of a project which is already late, by adding more people, will make the delivery even later. Brooks is clear that this is an over-simplification, however, the general reasoning is that given the ramp-up time of new resources and the communication overheads, in the immediate short-term velocity decreases. Also, many tasks may not be divisible, i.e. easily distributed between more resources, meaning the potential velocity increase is also lower.</p>\n<p>The common phrase in delivery &quot;Nine women can&#39;t make a baby in one month&quot; relates to Brooks&#39; Law, in particular, the fact that some kinds of work are not divisible or parallelisable.</p>\n<p>This is a central theme of the book &#39;<a href=\"#reading-list\">The Mythical Man Month</a>&#39;.</p>\n<ul>\n<li><a href=\"#todo\">Death March</a></li>\n<li><a href=\"#reading-list\">Reading List: The Mythical Man Month</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Brooks'+Law",
    "sourceUrl": "https://en.wikipedia.org/wiki/Brooks%27s_law",
    "seeAlso": []
  },
  {
    "id": "cap-theorem-brewers-theorem",
    "title": "CAP Theorem (Brewer's Theorem)",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<p>The CAP Theorem (defined by Eric Brewer) states that for a distributed data store only two out of the following three guarantees (at most) can be made:</p>\n<ul>\n<li>Consistency: when reading data, every request receives the <em>most recent</em> data or an error is returned</li>\n<li>Availability: when reading data, every request receives <em>a non error response</em>, without the guarantee that it is the <em>most recent</em> data</li>\n<li>Partition Tolerance: when an arbitrary number of network requests between nodes fail, the system continues to operate as expected</li>\n</ul>\n<p>The core of the reasoning is as follows. It is impossible to guarantee that a network partition will not occur (see <a href=\"#the-fallacies-of-distributed-computing\">The Fallacies of Distributed Computing</a>). Therefore in the case of a partition we can either cancel the operation (increasing consistency and decreasing availability) or proceed (increasing availability but decreasing consistency).</p>\n<p>The name comes from the first letters of the guarantees (Consistency, Availability, Partition Tolerance). Note that it is very important to be aware that this does <em>not</em> relate to <a href=\"#TODO\"><em>ACID</em></a>, which has a different definition of consistency. More recently, <a href=\"#TODO\">PACELC</a> theorem has been developed which adds constraints for latency and consistency when the network is <em>not</em> partitioned (i.e. when the system is operating as expected).</p>\n<p>Most modern database platforms acknowledge this theorem implicitly by offering the user of the database the option to choose between whether they want a highly available operation (which might include a &#39;dirty read&#39;) or a highly consistent operation (for example a &#39;quorum acknowledged write&#39;).</p>\n<p>Real world examples:</p>\n<ul>\n<li><a href=\"https://cloud.google.com/blog/products/gcp/inside-cloud-spanner-and-the-cap-theorem\">Inside Google Cloud Spanner and the CAP Theorem</a> - Goes into the details of how Cloud Spanner works, which appears at first to seem like a platform which has <em>all</em> of the guarantees of CAP, but under the hood is essentially a CP system.</li>\n</ul>\n<ul>\n<li><a href=\"#TODO\">ACID</a></li>\n<li><a href=\"#the-fallacies-of-distributed-computing\">The Fallacies of Distributed Computing</a></li>\n<li><a href=\"#TODO\">PACELC</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=CAP+Theorem+(Brewer's+Theorem)",
    "sourceUrl": null,
    "seeAlso": []
  },
  {
    "id": "clarkes-three-laws",
    "title": "Clarke's three laws",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<p>Arthur C. Clarke, an british science fiction writer, formulated three adages that are known as Clarke&#39;s three laws. The third law is the best known and most widely cited.  </p>\n<p>These so-called laws are:  </p>\n<ul>\n<li>When a distinguished but elderly scientist states that something is possible, they are almost certainly right. When they state that something is impossible, they are very probably wrong.</li>\n<li>The only way of discovering the limits of the possible is to venture a little way past them into the impossible.</li>\n<li>Any sufficiently advanced technology is indistinguishable from magic.</li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Clarke's+three+laws",
    "sourceUrl": "https://en.wikipedia.org/wiki/Clarke's_three_laws",
    "seeAlso": []
  },
  {
    "id": "conways-law",
    "title": "Conway's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<p>This law suggests that the technical boundaries of a system will reflect the structure of the organisation. It is commonly referred to when looking at organisation improvements, Conway&#39;s Law suggests that if an organisation is structured into many small, disconnected units, the software it produces will be. If an organisation is built more around &#39;verticals&#39; which are oriented around features or services, the software systems will also reflect this.</p>\n<ul>\n<li><a href=\"#the-spotify-model\">The Spotify Model</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Conway's+Law",
    "sourceUrl": "https://en.wikipedia.org/wiki/Conway%27s_law",
    "seeAlso": []
  },
  {
    "id": "cunninghams-law",
    "title": "Cunningham's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>The best way to get the right answer on the Internet is not to ask a question, it&#39;s to post the wrong answer.</p>\n</blockquote>\n<p>According to Steven McGeady, Ward Cunningham advised him in the early 1980s: &quot;The best way to get the right answer on the Internet is not to ask a question, it&#39;s to post the wrong answer.&quot; McGeady dubbed this Cunningham&#39;s law, though Cunningham denies ownership calling it a &quot;misquote.&quot; Although originally referring to interactions on Usenet, the law has been used to describe how other online communities work (e.g., Wikipedia, Reddit, Twitter, Facebook).</p>\n<ul>\n<li><a href=\"https://xkcd.com/386/\">XKCD 386: &quot;Duty Calls&quot;</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Cunningham's+Law",
    "sourceUrl": "https://en.wikipedia.org/wiki/Ward_Cunningham#Cunningham's_Law",
    "seeAlso": []
  },
  {
    "id": "dunbars-number",
    "title": "Dunbar's Number",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<p>&quot;Dunbar&#39;s number is a suggested cognitive limit to the number of people with whom one can maintain stable social relationships— relationships in which an individual knows who each person is and how each person relates to every other person.&quot; There is some disagreement to the exact number. &quot;... [Dunbar] proposed that humans can comfortably maintain only 150 stable relationships.&quot; He put the number into a more social context, &quot;the number of people you would not feel embarrassed about joining uninvited for a drink if you happened to bump into them in a bar.&quot; Estimates for the number generally lay between 100 and 250.</p>\n<p>Like stable relationships between individuals, a developer&#39;s relationship with a codebase takes effort to maintain. When faced with large complicated projects, or ownership of many projects, we lean on convention, policy, and modeled procedure to scale. Dunbar&#39;s number is not only important to keep in mind as an office grows, but also when setting the scope for team efforts or deciding when a system should invest in tooling to assist in modeling and automating logistical overhead. Putting the number into an engineering context, it is the number of projects (or normalized complexity of a single project) for which you would feel confident in joining an on-call rotation to support.</p>\n<ul>\n<li><a href=\"#conways-law\">Conway&#39;s Law</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Dunbar's+Number",
    "sourceUrl": "https://en.wikipedia.org/wiki/Dunbar%27s_number",
    "seeAlso": []
  },
  {
    "id": "the-dunning-kruger-effect",
    "title": "The Dunning-Kruger Effect",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>If you&#39;re incompetent, you can&#39;t know you&#39;re incompetent... The skills you need to produce a right answer are exactly the skills you need to recognize what a right answer is.</p>\n<p>(<a href=\"https://en.wikipedia.org/wiki/David_Dunning\">David Dunning</a>)</p>\n</blockquote>\n<p>The Dunning–Kruger effect is a theoretical cognitive bias which was described by David Dunning and Justin Kruger in a 1999 psychological study and paper. The study suggests that people with a low level of ability at a task are likely to overestimate their ability of the task. The proposed reason for this bias is that a sufficient <em>awareness</em> of the complexity of a problem or domain is required for a person to be able to make an informed opinion of their capability to work in that domain.</p>\n<p>The Dunning-Kruger effect has sometimes been used to describe a related, but not necessarily implied effect which could be described as &quot;The less a person understands a domain, the more they are likely to believe they can easily solve problems in that domain, as they are more likely to see the domain as <em>simple</em>&quot;. This more general effect is highly relevant in technology. It would suggest that people who are less familiar with a domain, such as non-technical team members or less experienced team members, are more likely to <em>underestimate</em> the effort required to solve a problem in this space.</p>\n<p>As a person&#39;s understanding and experience in a domain grows, they may well encounter another effect, which is that they tend to <em>overestimate</em> the ability of <em>others</em> or <em>underestimate</em> their own ability, as they are have become so experienced in the domain. In all cases these effects are <em>cognitive biases</em>. As with any bias, an understanding that it may be present will often be sufficient to help avoid the challenges — as when there is awareness of a bias, more inputs and opinions can be included to attempt to eliminate these biases. A closely related bias is that of <a href=\"https://en.wikipedia.org/wiki/Illusory_superiority\">Illusory superiority</a>.</p>\n<ul>\n<li><a href=\"https://fortune.com/2016/03/10/apple-fbi-lindsay-graham/\">Apple vs. FBI: Why This Anti-Terror Hawk Switched Sides</a> - In 2016 Senator Lindsey Graham changed his stance on Apple creating a &#39;backdoor&#39; in their encryption of devices. Initially Graham had been critical of Apple challenging a request to create a &#39;backdoor&#39;, which he saw as necessary to investigate potential terrorist plots. However, by Graham&#39;s own admission, as he learned more about the technical complexity of the domain, he realised that he had assumed it to be far more simple than he had realised, and that such a backdoor could have serious negative consequences. This could potentially be considered an example of the Dunning-Kruger effect - a cyber-security expert would likely understand immediately how such a backdoor could be exploited, as they have deep understanding of the domain, a layperson might assume that phone security is more similar to <em>physical security</em> where the practice of having a &#39;master key&#39; for law enforcement is possible, but this analogy does not apply sufficiently well to describe modern encryption in cyber-security.</li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Dunning-Kruger+Effect",
    "sourceUrl": "https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect",
    "seeAlso": []
  },
  {
    "id": "fitts-law",
    "title": "Fitts' Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<p>Fitts&#39; law predicts that the time required to move to a target area is a function of the distance to the target divided by the width of the target.</p>\n<img width=\"300px\" alt=\"Diagram: Fitts Law\" src=\"./images/Fitts_Law.svg\" />\n\n<p><em>(Image Reference: By Foobar628 at English Wikipedia, Creative Commons Attribution-Share Alike 3.0 Unported, <a href=\"https://en.wikipedia.org/wiki/Fitts%27s_law#/media/File:Fitts_Law.svg\">https://en.wikipedia.org/wiki/Fitts%27s_law#/media/File:Fitts_Law.svg</a>)</em></p>\n<p>The consequences of this law dictate that when designing UX or UI, interactive elements should be as large as possible and the distance between the users attention area and interactive element should be as small as possible. This has consequences on design, such as grouping tasks that are commonly used with one another close.</p>\n<p>It also formalises the concept of &#39;magic corners&#39;, the corners of the screen to which a user can &#39;sweep&#39; their mouse to easily hit - which is where key UI elements can be placed. The Windows Start button is in a magic corner, making it easy to select, and as an interesting contrast, the MacOS &#39;close window&#39; button is <em>not</em> in a magic corner, making it hard to hit by mistake.</p>\n<ul>\n<li><a href=\"https://www.semanticscholar.org/paper/The-information-capacity-of-the-human-motor-system-Fitts/634c9fde5f1c411e4487658ac738dcf18d98ea8d\">The information capacity of the human motor system in controlling the amplitude of movement.</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Fitts'+Law",
    "sourceUrl": "https://en.wikipedia.org/wiki/Fitts%27s_law",
    "seeAlso": []
  },
  {
    "id": "galls-law",
    "title": "Gall's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>A complex system that works is invariably found to have evolved from a simple system that worked. A complex system designed from scratch never works and cannot be patched up to make it work. You have to start over with a working simple system.</p>\n<p>(<a href=\"https://en.wikipedia.org/wiki/John_Gall_(author)\">John Gall</a>)</p>\n</blockquote>\n<p>Gall&#39;s Law implies that attempts to <em>design</em> highly complex systems are likely to fail. Highly complex systems are rarely built in one go, but evolve instead from more simple systems.</p>\n<p>The classic example is the world-wide-web. In its current state, it is a highly complex system. However, it was defined initially as a simple way to share content between academic institutions. It was very successful in meeting these goals and evolved to become more complex over time.</p>\n<ul>\n<li><a href=\"#the-kiss-principle\">KISS (Keep It Simple, Stupid)</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Gall's+Law",
    "sourceUrl": "https://en.wikipedia.org/wiki/John_Gall_(author)#Gall's_law",
    "seeAlso": []
  },
  {
    "id": "goodharts-law",
    "title": "Goodhart's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>Any observed statistical regularity will tend to collapse once pressure is placed upon it for control purposes.</p>\n<p><em>Charles Goodhart</em></p>\n</blockquote>\n<p>Also commonly referenced as:</p>\n<blockquote>\n<p>When a measure becomes a target, it ceases to be a good measure.</p>\n<p><em>Marilyn Strathern</em></p>\n</blockquote>\n<p>The law states that the measure-driven optimizations could lead to devaluation of the measurement outcome itself. Overly selective set of measures (<a href=\"https://en.wikipedia.org/wiki/Performance_indicator\">KPIs</a>) blindly applied to a process results in distorted effect. People tend to optimize locally by &quot;gaming&quot; the system in order to satisfy particular metrics instead of paying attention to holistic outcome of their actions.</p>\n",
    "examples": [
      "Assert-free tests satisfy the code coverage expectation, despite the fact that the metric intent was to create well-tested software.",
      "Developer performance score indicated by the number of lines committed leads to unjustifiably bloated codebase."
    ],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Goodhart's+Law",
    "sourceUrl": "https://en.wikipedia.org/wiki/Goodhart's_law",
    "seeAlso": [
      "[Goodhart’s Law: How Measuring The Wrong Things Drive Immoral Behaviour](https://coffeeandjunk.com/goodharts-campbells-law/)",
      "[Dilbert on bug-free software](https://dilbert.com/strip/1995-11-13)"
    ]
  },
  {
    "id": "hanlons-razor",
    "title": "Hanlon's Razor",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>Never attribute to malice that which is adequately explained by stupidity.</p>\n<p>Robert J. Hanlon</p>\n</blockquote>\n<p>This principle suggests that actions resulting in a negative outcome were not a result of ill will. Instead the negative outcome is more likely attributed to those actions and/or the impact being not fully understood.</p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Hanlon's+Razor",
    "sourceUrl": "https://en.wikipedia.org/wiki/Hanlon%27s_razor",
    "seeAlso": []
  },
  {
    "id": "hicks-law-hick-hyman-law",
    "title": "Hick's Law (Hick-Hyman Law)",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>Decision time grows logarithmically with the number of options you can choose from.</p>\n<p>William Edmund Hick and Ray Hyman</p>\n</blockquote>\n<p>In the equation below, <code>T</code> is the time to make a decision, <code>n</code> is the number of options, and <code>b</code> is a constant which is determined by analysis of the data.</p>\n<p><em>(Image Reference: Creative Commons Attribution-Share Alike 3.0 Unported, <a href=\"https://en.wikipedia.org/wiki/Hick%27s_law\">https://en.wikipedia.org/wiki/Hick%27s_law</a>)</em></p>\n<p>This law only applies when the number of options is <em>ordered</em>, for example, alphabetically. This is implied in the base two logarithm - which implies the decision maker is essentially performing a <em>binary search</em>. If the options are not well ordered, experiments show the time taken is linear.</p>\n<p>This is has significant impact in UI design; ensuring that users can easily search through options leads to faster decision making.</p>\n<p>A correlation has also been shown in Hick&#39;s Law between IQ and reaction time as shown in <a href=\"https://www.sciencedirect.com/science/article/pii/S0022440599000369\">Speed of Information Processing: Developmental Change and Links to Intelligence</a>.</p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "./images/hicks_law.svg",
    "sourceUrl": "https://en.wikipedia.org/wiki/Hick%27s_law",
    "seeAlso": [
      "[Fitts's Law](#fitts-law)"
    ]
  },
  {
    "id": "hofstadters-law",
    "title": "Hofstadter's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>It always takes longer than you expect, even when you take into account Hofstadter&#39;s Law.</p>\n<p>(Douglas Hofstadter)</p>\n</blockquote>\n<p>You might hear this law referred to when looking at estimates for how long something will take. It seems a truism in software development that we tend to not be very good at accurately estimating how long something will take to deliver.</p>\n<p>This is from the book &#39;<a href=\"#reading-list\">Gödel, Escher, Bach: An Eternal Golden Braid</a>&#39;.</p>\n<ul>\n<li><a href=\"#reading-list\">Reading List: Gödel, Escher, Bach: An Eternal Golden Braid</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Hofstadter's+Law",
    "sourceUrl": "https://en.wikipedia.org/wiki/Hofstadter%27s_law",
    "seeAlso": []
  },
  {
    "id": "hutbers-law",
    "title": "Hutber's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>Improvement means deterioration.</p>\n<p>(<a href=\"https://en.wikipedia.org/wiki/Patrick_Hutber\">Patrick Hutber</a>)</p>\n</blockquote>\n<p>This law suggests that improvements to a system will lead to deterioration in other parts, or it will hide other deterioration, leading overall to a degradation from the current state of the system.</p>\n<p>For example, a decrease in response latency for a particular end-point could cause increased throughput and capacity issues further along in a request flow, affecting an entirely different sub-system.</p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Hutber's+Law",
    "sourceUrl": "https://en.wikipedia.org/wiki/Hutber%27s_law",
    "seeAlso": []
  },
  {
    "id": "the-hype-cycle-amaras-law",
    "title": "The Hype Cycle & Amara's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>We tend to overestimate the effect of a technology in the short run and underestimate the effect in the long run.</p>\n<p>(Roy Amara)</p>\n</blockquote>\n<p>The Hype Cycle is a visual representation of the excitement and development of technology over time, originally produced by Gartner. It is best shown with a visual:</p>\n<p><em>(Image Reference: By Jeremykemp at English Wikipedia, CC BY-SA 3.0, <a href=\"https://commons.wikimedia.org/w/index.php?curid=10547051\">https://commons.wikimedia.org/w/index.php?curid=10547051</a>)</em></p>\n<p>In short, this cycle suggests that there is typically a burst of excitement around new technology and its potential impact. Teams often jump into these technologies quickly, and sometimes find themselves disappointed with the results. This might be because the technology is not yet mature enough, or real-world applications are not yet fully realised. After a certain amount of time, the capabilities of the technology increase and practical opportunities to use it increase, and teams can finally become productive. Roy Amara&#39;s quote sums this up most succinctly - &quot;We tend to overestimate the effect of a technology in the short run and underestimate in the long run&quot;.</p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "./images/gartner_hype_cycle.png",
    "sourceUrl": "https://en.wikipedia.org/wiki/Hype_cycle",
    "seeAlso": []
  },
  {
    "id": "hyrums-law-the-law-of-implicit-interfaces",
    "title": "Hyrum's Law (The Law of Implicit Interfaces)",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>With a sufficient number of users of an API,\nit does not matter what you promise in the contract:\nall observable behaviours of your system\nwill be depended on by somebody.</p>\n<p>(Hyrum Wright)</p>\n</blockquote>\n<p>Hyrum&#39;s Law states that when you have a <em>large enough number of consumers</em> of an API, all behaviours of the API (even those not defined as part of a public contract) will eventually come to be depended on by someone. A trivial example may be non-functional elements such as the response time of an API. A more subtle example might be consumers who are relying on applying a regex to an error message to determine the <em>type</em> of error of an API. Even if the public contract of the API states nothing about the contents of the message, indicating users should use an associated error code, <em>some</em> users may use the message, and changing the message essentially breaks the API for those users.</p>\n<ul>\n<li><a href=\"#the-law-of-leaky-abstractions\">The Law of Leaky Abstractions</a></li>\n<li><a href=\"https://xkcd.com/1172/\">XKCD 1172</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Hyrum's+Law+(The+Law+of+Implicit+Interfaces)",
    "sourceUrl": "http://www.hyrumslaw.com/",
    "seeAlso": []
  },
  {
    "id": "input-process-output-ipo",
    "title": "Input-Process-Output (IPO)",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<p>Systems can be incredibly complex, but can typically be broken down into smaller parts that follow a simple pattern:</p>\n<ol>\n<li>Input is provided</li>\n<li>Some kind of processing or transformation is performed</li>\n<li>Output is returned</li>\n</ol>\n<p>A sort function in a programming language or system could be a classic example of the IPO pattern; where arbitrary input is sorted based on a predicate and returned back. A web server could be modelled as an IPO system, where HTTP requests are transformed into HTTP responses. A highly complex Generative AI system could likewise be modelled in this way, with user input being passed through a complex model and a response being generated.</p>\n<p>The IPO pattern is present in different forms across almost all technological domains, from <a href=\"https://en.wikipedia.org/wiki/Functional_programming\">functional programming</a> languages that explicitly follow IPO patterns to <a href=\"#the-unix-philosophy\">The Unix Philosophy</a>, which suggests that highly complex systems can be built by chaining together many simple IPO programs.</p>\n<ul>\n<li><a href=\"#the-unix-philosophy\">The Unix Philosophy</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Input-Process-Output+(IPO)",
    "sourceUrl": "https://en.wikipedia.org/wiki/IPO_model",
    "seeAlso": []
  },
  {
    "id": "kernighans-law",
    "title": "Kernighan's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.</p>\n<p>(Brian Kernighan)</p>\n</blockquote>\n<p>Kernighan&#39;s Law is named for <a href=\"https://en.wikipedia.org/wiki/Brian_Kernighan\">Brian Kernighan</a> and derived from a quote from Kernighan and Plauger&#39;s book <a href=\"https://en.wikipedia.org/wiki/The_Elements_of_Programming_Style\">The Elements of Programming Style</a>:</p>\n<blockquote>\n<p>Everyone knows that debugging is twice as hard as writing a program in the first place. So if you&#39;re as clever as you can be when you write it, how will you ever debug it?</p>\n</blockquote>\n<p>While hyperbolic, Kernighan&#39;s Law makes the argument that simple code is to be preferred over complex code, because debugging any issues that arise in complex code may be costly or even infeasible.</p>\n<ul>\n<li><a href=\"#the-kiss-principle\">The KISS Principle</a></li>\n<li><a href=\"#the-unix-philosophy\">The Unix Philosophy</a></li>\n<li><a href=\"#occams-razor\">Occam&#39;s Razor</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Kernighan's+Law",
    "sourceUrl": null,
    "seeAlso": []
  },
  {
    "id": "linuss-law",
    "title": "Linus's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>Given enough eyeballs, all bugs are shallow.</p>\n<p><em>Eric S. Raymond</em></p>\n</blockquote>\n<p>This law simply states that the more people who can see a problem, the higher the likelihood that someone will have seen and solved the problem before, or something very similar.</p>\n<p>Although it was originally used to describe the value of open-source models for projects it can be accepted for any kind of software project. It can also be extended to processes - more code reviews, more static analysis and multi-disciplined test processes will make the problems more visible and easy to identify.</p>\n<p>A more formal statement can be:</p>\n<blockquote>\n<p>Given a large enough beta-tester and co-developer base, almost every problem will be characterized quickly and can be solved by someone who has encountered a similar problem before.</p>\n</blockquote>\n<p>This law was named in honour of <a href=\"https://en.wikipedia.org/wiki/Linus_Torvalds\">Linus Torvalds</a> in Eric S. Raymond&#39;s book &quot;<a href=\"https://en.wikipedia.org/wiki/The_Cathedral_and_the_Bazaar\">The Cathedral and the Bazaar</a>&quot;.</p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Linus's+Law",
    "sourceUrl": "https://en.wikipedia.org/wiki/Linus%27s_law",
    "seeAlso": []
  },
  {
    "id": "metcalfes-law",
    "title": "Metcalfe's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>In network theory, the value of a system grows as approximately the square of the number of users of the system.</p>\n</blockquote>\n<p>This law is based on the number of possible pairwise connections within a system and is closely related to <a href=\"#reeds-law\">Reed&#39;s Law</a>. Odlyzko and others have argued that both Reed&#39;s Law and Metcalfe&#39;s Law overstate the value of the system by not accounting for the limits of human cognition on network effects; see <a href=\"#dunbars-number\">Dunbar&#39;s Number</a>.</p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Metcalfe's+Law",
    "sourceUrl": "https://en.wikipedia.org/wiki/Metcalfe's_law",
    "seeAlso": [
      "[Reed's Law](#reeds-law)",
      "[Dunbar's Number](#dunbars-number)"
    ]
  },
  {
    "id": "moores-law",
    "title": "Moore's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>The number of transistors in an integrated circuit doubles approximately every two years.</p>\n</blockquote>\n<p>Often used to illustrate the sheer speed at which semiconductor and chip technology has improved, Moore&#39;s prediction has proven to be highly accurate over from the 1970s to the late 2000s. In more recent years, the trend has changed slightly, partly due to <a href=\"https://en.wikipedia.org/wiki/Quantum_tunnelling\">physical limitations on the degree to which components can be miniaturised</a>. However, advancements in parallelisation, and potentially revolutionary changes in semiconductor technology and quantum computing may mean that Moore&#39;s Law could continue to hold true for decades to come.</p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Moore's+Law",
    "sourceUrl": "https://en.wikipedia.org/wiki/Moore%27s_law",
    "seeAlso": []
  },
  {
    "id": "murphys-law-sods-law",
    "title": "Murphy's Law / Sod's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>Anything that can go wrong will go wrong.</p>\n</blockquote>\n<p>Related to <a href=\"https://en.wikipedia.org/wiki/Edward_A._Murphy_Jr.\">Edward A. Murphy, Jr</a> <em>Murphy&#39;s Law</em> states that if a thing can go wrong, it will go wrong.</p>\n<p>This is a common adage among developers. Sometimes the unexpected happens when developing, testing or even in production. This can also be related to the (more common in British English) <em>Sod&#39;s Law</em>:</p>\n<blockquote>\n<p>If something can go wrong, it will, at the worst possible time.</p>\n</blockquote>\n<p>These &#39;laws&#39; are generally used in a comic sense. However, phenomena such as <a href=\"#TODO\"><em>Confirmation Bias</em></a> and <a href=\"#TODO\"><em>Selection Bias</em></a> can lead people to perhaps over-emphasise these laws (the majority of times when things work, they go unnoticed, failures however are more noticeable and draw more discussion).</p>\n<ul>\n<li><a href=\"#TODO\">Confirmation Bias</a></li>\n<li><a href=\"#TODO\">Selection Bias</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Murphy's+Law+%2F+Sod's+Law",
    "sourceUrl": "https://en.wikipedia.org/wiki/Murphy%27s_law",
    "seeAlso": []
  },
  {
    "id": "occams-razor",
    "title": "Occam's Razor",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>Entities should not be multiplied without necessity.</p>\n<p>William of Ockham</p>\n</blockquote>\n<p>Occam&#39;s razor says that among several possible solutions, the most likely solution is the one with the least number of concepts and assumptions. This solution is the simplest and solves only the given problem, without introducing accidental complexity and possible negative consequences.</p>\n<ul>\n<li><a href=\"#yagni\">YAGNI</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/No_Silver_Bullet\">No Silver Bullet: Accidental Complexity and Essential Complexity</a></li>\n</ul>\n<p>Example:</p>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Lean_software_development#Eliminate_waste\">Lean Software Development: Eliminate Waste</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Occam's+Razor",
    "sourceUrl": "https://en.wikipedia.org/wiki/Occam's_razor",
    "seeAlso": []
  },
  {
    "id": "parkinsons-law",
    "title": "Parkinson's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>Work expands so as to fill the time available for its completion.</p>\n</blockquote>\n<p>In its original context, this Law was based on studies of bureaucracies. It may be pessimistically applied to software development initiatives, the theory being that teams will be inefficient until deadlines near, then rush to complete work by the deadline, thus making the actual deadline somewhat arbitrary.</p>\n<p>If this law were combined with <a href=\"#hofstadters-law\">Hofstadter&#39;s Law</a>, an even more pessimistic viewpoint is reached - work will expand to fill the time available for its completion and <em>still take longer than expected</em>.</p>\n<ul>\n<li><a href=\"#hofstadters-law\">Hofstadter&#39;s Law</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Parkinson's+Law",
    "sourceUrl": "https://en.wikipedia.org/wiki/Parkinson%27s_law",
    "seeAlso": []
  },
  {
    "id": "premature-optimization-effect",
    "title": "Premature Optimization Effect",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>Premature optimization is the root of all evil.</p>\n<p><a href=\"https://twitter.com/realdonaldknuth?lang=en\">(Donald Knuth)</a></p>\n</blockquote>\n<p>In Donald Knuth&#39;s paper <a href=\"http://wiki.c2.com/?StructuredProgrammingWithGoToStatements\">Structured Programming With Go To Statements</a>, he wrote: &quot;Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered. We should forget about small efficiencies, say about 97% of the time: <strong>premature optimization is the root of all evil</strong>. Yet we should not pass up our opportunities in that critical 3%.&quot;</p>\n<p>However, <em>Premature Optimization</em> can be defined (in less loaded terms) as optimizing before we know that we need to.</p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Premature+Optimization+Effect",
    "sourceUrl": "http://wiki.c2.com/?PrematureOptimization",
    "seeAlso": []
  },
  {
    "id": "putts-law",
    "title": "Putt's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>Technology is dominated by two types of people, those who understand what they do not manage and those who manage what they do not understand.</p>\n</blockquote>\n<p>Putt&#39;s Law is often followed by Putt&#39;s Corollary:</p>\n<blockquote>\n<p>Every technical hierarchy, in time, develops a competence inversion.</p>\n</blockquote>\n<p>These statements suggest that due to various selection criteria and trends in how groups organise, there will be a number of skilled people at working levels of a technical organisations, and a number of people in managerial roles who are not aware of the complexities and challenges of the work they are managing. This can be due to phenomena such as <a href=\"#the-peter-principle\">The Peter Principle</a> or <a href=\"#the-dilbert-principle\">The Dilbert Principle</a>.</p>\n<p>However, it should be stressed that Laws such as this are vast generalisations and may apply to <em>some</em> types of organisations, and not apply to others.</p>\n<ul>\n<li><a href=\"#the-peter-principle\">The Peter Principle</a></li>\n<li><a href=\"#the-dilbert-principle\">The Dilbert Principle</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Putt's+Law",
    "sourceUrl": "https://en.wikipedia.org/wiki/Putt%27s_Law_and_the_Successful_Technocrat",
    "seeAlso": []
  },
  {
    "id": "reeds-law",
    "title": "Reed's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>The utility of large networks, particularly social networks, scales exponentially with the size of the network.</p>\n</blockquote>\n<p>This law is based on graph theory, where the utility scales as the number of possible sub-groups, which is faster than the number of participants or the number of possible pairwise connections. Odlyzko and others have argued that Reed&#39;s Law overstates the utility of the system by not accounting for the limits of human cognition on network effects; see <a href=\"#dunbars-number\">Dunbar&#39;s Number</a>.</p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Reed's+Law",
    "sourceUrl": "https://en.wikipedia.org/wiki/Reed's_law",
    "seeAlso": [
      "[Metcalfe's Law](#metcalfes-law)",
      "[Dunbar's Number](#dunbars-number)"
    ]
  },
  {
    "id": "the-ringelmann-effect",
    "title": "The Ringelmann Effect",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<p>The Ringelmann Effect is the tendency of an individual to become increasingly inefficient as more and more people are involved in a task. In other words, as more individuals are added to a team, the more the average individual performance decreases. Multiple causes are believed to be at work, including loss of motivation (&quot;<a href=\"https://en.wikipedia.org/wiki/Social_loafing\">social loafing</a>&quot;) and challenges related to coordination.</p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Ringelmann+Effect",
    "sourceUrl": "https://en.wikipedia.org/wiki/Ringelmann_effect",
    "seeAlso": [
      "[Brooks' Law](#brooks-law)"
    ]
  },
  {
    "id": "the-law-of-conservation-of-complexity-teslers-law",
    "title": "The Law of Conservation of Complexity (Tesler's Law)",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<p>This law states that there is a certain amount of complexity in a system which cannot be reduced.</p>\n<p>Some complexity in a system is &#39;inadvertent&#39;. It is a consequence of poor structure, mistakes, or just bad modeling of a problem to solve. Inadvertent complexity can be reduced (or eliminated). However, some complexity is &#39;intrinsic&#39; as a consequence of the complexity inherent in the problem being solved. This complexity can be moved, but not eliminated.</p>\n<p>One interesting element to this law is the suggestion that even by simplifying the entire system, the intrinsic complexity is not reduced, it is <em>moved to the user</em>, who must behave in a more complex way.</p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Law+of+Conservation+of+Complexity+(Tesler's+Law)",
    "sourceUrl": "https://en.wikipedia.org/wiki/Law_of_conservation_of_complexity",
    "seeAlso": []
  },
  {
    "id": "the-law-of-demeter",
    "title": "The Law of Demeter",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>Don&#39;t talk to strangers.</p>\n</blockquote>\n<p>The Law of Demeter, also known as &quot;The Principle of Least Knowledge&quot; is a principle for software design, particularly relevant in object orientated languages.</p>\n<p>It states that a unit of software should talk only to its immediate collaborators. An object <code>A</code> with a reference to object <code>B</code> can call its methods, but if <code>B</code> has a reference to object <code>C</code>, <code>A</code> should not call <code>C</code>s methods. So, if <code>C</code> has a <code>doThing()</code> method, <code>A</code> should not invoke it directly; <code>B.getC().doThis()</code>.</p>\n<p>Following this principal limits the scope of changes, making them easier and safer in future.</p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Law+of+Demeter",
    "sourceUrl": "https://en.wikipedia.org/wiki/Law_of_Demeter",
    "seeAlso": []
  },
  {
    "id": "the-law-of-leaky-abstractions",
    "title": "The Law of Leaky Abstractions",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>All non-trivial abstractions, to some degree, are leaky.</p>\n<p>(<a href=\"https://twitter.com/spolsky\">Joel Spolsky</a>)</p>\n</blockquote>\n<p>This law states that abstractions, which are generally used in computing to simplify working with complicated systems, will in certain situations &#39;leak&#39; elements of the underlying system, this making the abstraction behave in an unexpected way.</p>\n<p>An example might be loading a file and reading its contents. The file system APIs are an <em>abstraction</em> of the lower level kernel systems, which are themselves an abstraction over the physical processes relating to changing data on a magnetic platter (or flash memory for an SSD). In most cases, the abstraction of treating a file like a stream of binary data will work. However, for a magnetic drive, reading data sequentially will be <em>significantly</em> faster than random access (due to increased overhead of page faults), but for an SSD drive, this overhead will not be present. Underlying details will need to be understood to deal with this case (for example, database index files are structured to reduce the overhead of random access), the abstraction &#39;leaks&#39; implementation details the developer may need to be aware of.</p>\n<p>The example above can become more complex when <em>more</em> abstractions are introduced. The Linux operating system allows files to be accessed over a network but represented locally as &#39;normal&#39; files. This abstraction will &#39;leak&#39; if there are network failures. If a developer treats these files as &#39;normal&#39; files, without considering the fact that they may be subject to network latency and failures, the solutions will be buggy.</p>\n<p>The article describing the law suggests that an over-reliance on abstractions, combined with a poor understanding of the underlying processes, actually makes dealing with the problem at hand <em>more</em> complex in some cases.</p>\n<ul>\n<li><a href=\"#hyrums-law-the-law-of-implicit-interfaces\">Hyrum&#39;s Law</a></li>\n</ul>\n<ul>\n<li><a href=\"https://forums.adobe.com/thread/376152\">Photoshop Slow Startup</a> - an issue I encountered in the past. Photoshop would be slow to startup, sometimes taking minutes. It seems the issue was that on startup it reads some information about the current default printer. However, if that printer is actually a network printer, this could take an extremely long time. The <em>abstraction</em> of a network printer being presented to the system similar to a local printer caused an issue for users in poor connectivity situations.</li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Law+of+Leaky+Abstractions",
    "sourceUrl": "https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/",
    "seeAlso": []
  },
  {
    "id": "the-law-of-the-instrument",
    "title": "The Law of the Instrument",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>I call it the law of the instrument, and it may be formulated as follows: Give a small boy a hammer, and he will find that everything he encounters needs pounding.</p>\n<p><em>Abraham Kaplan</em></p>\n</blockquote>\n<blockquote>\n<p>If all you have is a hammer, everything looks like a nail.</p>\n<p><em>Abraham Maslow</em></p>\n</blockquote>\n<p>In the context of computer programming, this law suggests that people tend to use tools that are familiar with, rather than the best possible tool. This over-reliance on a familiar tool is an anti-pattern referred to as &#39;the golden hammer&#39;.</p>\n<ul>\n<li><a href=\"https://josemdev.com/avoiding-the-law-of-the-instrument/\">Avoiding the law of the instrument</a></li>\n<li><a href=\"https://archive.org/details/antipatternsrefa0000unse/page/111/mode/2up\">Anti-Pattern - The Golden Hammer</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Law+of+the+Instrument",
    "sourceUrl": "https://en.wikipedia.org/wiki/Law_of_the_instrument",
    "seeAlso": []
  },
  {
    "id": "the-law-of-triviality",
    "title": "The Law of Triviality",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<p>This law suggests that groups will give far more time and attention to trivial or cosmetic issues rather than serious and substantial ones.</p>\n<p>The common fictional example used is that of a committee approving plans for nuclear power plant, who spend the majority of their time discussing the structure of the bike shed, rather than the far more important design for the power plant itself. It can be difficult to give valuable input on discussions about very large, complex topics without a high degree of subject matter expertise or preparation. However, people want to be seen to be contributing valuable input. Hence a tendency to focus too much time on small details, which can be reasoned about easily, but are not necessarily of particular importance.</p>\n<p>The fictional example above led to the usage of the term &#39;Bike Shedding&#39; as an expression for wasting time on trivial details. A related term is &#39;<a href=\"https://en.wiktionary.org/wiki/yak_shaving\">Yak Shaving</a>,&#39; which connotes a seemingly irrelevant activity that is part of a long chain of prerequisites to the main task.</p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Law+of+Triviality",
    "sourceUrl": "https://en.wikipedia.org/wiki/Law_of_triviality",
    "seeAlso": []
  },
  {
    "id": "the-unix-philosophy",
    "title": "The Unix Philosophy",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<p>The Unix Philosophy is that software components should be small, and focused on doing one specific thing well. This can make it easier to build systems by composing together small, simple, well-defined units, rather than using large, complex, multi-purpose programs.</p>\n<p>Modern practices like &#39;Microservice Architecture&#39; can be thought of as an application of this law, where services are small, focused and do one specific thing, allowing complex behaviour to be composed of simple building blocks.</p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Unix+Philosophy",
    "sourceUrl": "https://en.wikipedia.org/wiki/Unix_philosophy",
    "seeAlso": []
  },
  {
    "id": "the-scout-rule",
    "title": "The Scout Rule",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>Always leave the code better than you found it.</p>\n<p>(Robert C. Martin (Uncle Bob))</p>\n</blockquote>\n<p>Based on the &quot;Scout Rule&quot;, which is &quot;always leave the campground cleaner than you found it&quot;, the Scout Rule in programming is simply &quot;always leave the code cleaner than you found it&quot;.</p>\n<p>This was introduced in the first chapter of the book <a href=\"https://www.goodreads.com/book/show/3735293-clean-code\">Clean Code</a> by Bob Martin. The rule suggests that developers should perform &#39;optimistic refactoring&#39;, which means to endeavour to improve the overall quality of the code when you work on it. If you see a mistake, attempt to fix it or clean it up. However, when making changes to code which seems incorrect, it may be worth remembering <a href=\"#chestertons-fence\">Chesterton&#39;s Fence</a>!</p>\n<ul>\n<li><a href=\"#reading-list\">Reading List: Clean Code</a></li>\n<li><a href=\"#chestertons-fence\">Chesterton&#39;s Fence</a></li>\n<li><a href=\"#broken-windows-theory\">The Broken Windows Theory</a></li>\n</ul>\n<p><a href=\"https://www.amazon.sg/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882\">https://www.amazon.sg/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882</a></p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Scout+Rule",
    "sourceUrl": "https://www.oreilly.com/library/view/97-things-every/9780596809515/ch08.html",
    "seeAlso": []
  },
  {
    "id": "the-spotify-model",
    "title": "The Spotify Model",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<p>The Spotify Model is an approach to team and organisation structure which has been popularised by &#39;Spotify&#39;. In this model, teams are organised around features, rather than technologies.</p>\n<p>The Spotify Model also popularises the concepts of Tribes, Guilds, Chapters, which are other components of their organisation structure.</p>\n<p>Members of the organisation have described that the actual meaning of these groups changes, evolves and is an on-going experiment. The fact that the model is a <em>process in motion</em>, rather than a fixed model continues to lead to varying interpretations of the structure, which may be based on presentations given by employees at conferences. This means &#39;snapshots&#39; may be &#39;re-packaged&#39; by third parties as a <em>fixed structure</em>, with the fact that the model is dynamic being lost.</p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Spotify+Model",
    "sourceUrl": "https://labs.spotify.com/2014/03/27/spotify-engineering-culture-part-1/",
    "seeAlso": []
  },
  {
    "id": "the-two-pizza-rule",
    "title": "The Two Pizza Rule",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>If you can&#39;t feed a team with two pizzas, it&#39;s too large.</p>\n<p>(Jeff Bezos)</p>\n</blockquote>\n<p>This rule suggests that regardless of the size of the company, teams should be small enough to be fed by two pizzas. Attributed to Jeff Bezos and Amazon, this belief suggests that large teams are inherently inefficient. This is supported by the fact that as the team size increases linearly, the links between people increases quadratically; thus the cost of coordinating and communicating also grows quadratically. If this cost of coordination is essentially overhead, then smaller teams should be preferred.</p>\n<p>The number of links between people can be expressed as <code>n(n-1)/2</code> where n = number of people.</p>\n<img width=\"200px\" alt=\"Complete graph; Links between people\" src=\"./images/complete_graph.png\" />\n\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Two+Pizza+Rule",
    "sourceUrl": null,
    "seeAlso": []
  },
  {
    "id": "twymans-law",
    "title": "Twyman's law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>The more unusual or interesting the data, the more likely they are to have been the result of an error of one kind or another.</p>\n</blockquote>\n<p>This law suggests that when there are particularly unusual data points, it is more likely that they are the result of errors or manipulation. For example, if a dataset of long-jump results from a sporting event showed a maximum value of 20 meters (more than twice the world record), it is more likely to be due to an error (such as recording a value in feet rather than meters) than due to an unusually long jump. It is also more likely in this case that the results could have been manipulated.</p>\n<ul>\n<li><a href=\"#TODO\">Sagan Standard</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Twyman's+law",
    "sourceUrl": "https://en.wikipedia.org/wiki/Twyman%27s_law",
    "seeAlso": []
  },
  {
    "id": "wadlers-law",
    "title": "Wadler's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<blockquote>\n<p>In any language design, the total time spent discussing a feature in this list is proportional to two raised to the power of its position.</p>\n<ol start=\"0\">\n<li>Semantics</li>\n<li>Syntax</li>\n<li>Lexical syntax</li>\n<li>Lexical syntax of comments</li>\n</ol>\n<p>(In short, for every hour spent on semantics, 8 hours will be spent on the syntax of comments).</p>\n</blockquote>\n<p>Similar to <a href=\"#the-law-of-triviality\">The Law of Triviality</a>, Wadler&#39;s Law states what when designing a language, the amount of time spent on language structures is disproportionately high in comparison to the importance of those features.</p>\n<ul>\n<li><a href=\"#the-law-of-triviality\">The Law of Triviality</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Wadler's+Law",
    "sourceUrl": "https://wiki.haskell.org/Wadler's_Law",
    "seeAlso": []
  },
  {
    "id": "wheatons-law",
    "title": "Wheaton's Law",
    "category": "Laws",
    "type": "law",
    "icon": "⚖️",
    "description": "<p><a href=\"https://dontbeadickday.com/\">The Official Day</a></p>\n<blockquote>\n<p>Don&#39;t be a dick.</p>\n<p><em>Wil Wheaton</em></p>\n</blockquote>\n<p>Coined by Wil Wheaton (Star Trek: The Next Generation, The Big Bang Theory), this simple, concise, and powerful law aims for an increase in harmony and respect within a professional organization. It can be applied when speaking with coworkers, performing code reviews, countering other points of view, critiquing, and in general, most professional interactions humans have with each other.</p>\n",
    "examples": [],
    "tags": [
      "law"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Wheaton's+Law",
    "sourceUrl": "http://www.wheatonslaw.com/",
    "seeAlso": []
  },
  {
    "id": "all-models-are-wrong-george-boxs-law",
    "title": "All Models Are Wrong (George Box's Law)",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>All models are wrong, but some are useful.</p>\n<p><em>George Box</em></p>\n</blockquote>\n<p>This principle suggests that all models of systems are flawed, but that as long as they are not <em>too</em> flawed they may be useful. This principle has its roots in statistics but applies to scientific and computing models as well.</p>\n<p>A fundamental requirement of most software is to model a system of some kind. Regardless of whether the system being modeled is a computer network, a library, a graph of social connections or any other kind of system, the designer will have to decide an appropriate level of detail to model. Excessive detail may lead to too much complexity, too little detail may prevent the model from being functional.</p>\n<ul>\n<li><a href=\"#the-law-of-leaky-abstractions\">The Law of Leaky Abstractions</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=All+Models+Are+Wrong+(George+Box's+Law)",
    "sourceUrl": "https://en.wikipedia.org/wiki/All_models_are_wrong",
    "seeAlso": []
  },
  {
    "id": "chestertons-fence",
    "title": "Chesterton's Fence",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>Reforms should not be made until the reasoning behind the existing state of affairs is understood.</p>\n</blockquote>\n<p>This principle is relevant in software engineering when removing technical debt. Each line of a program was originally written by someone for some reason. Chesterton&#39;s Fence suggests that one should try to understand the context and meaning of the code fully, before changing or removing it, even if at first glance it seems redundant or incorrect.</p>\n<p>The name of this principle comes from a story by <a href=\"https://en.wikipedia.org/wiki/G._K._Chesterton\">G.K. Chesterton</a>. A man comes across a fence crossing the middle of the road. He complains to the mayor that this useless fence is getting in the way, and asks to remove it. The mayor asks why the fence is there in the first place. When the man says he doesn&#39;t know, the mayor says, &quot;If you don&#39;t know its purpose, I certainly won&#39;t let you remove it. Go and find out the use of it, and then I may let you destroy it.&quot;</p>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Chesterton's+Fence",
    "sourceUrl": "https://en.wikipedia.org/wiki/Wikipedia:Chesterton%27s_fence",
    "seeAlso": []
  },
  {
    "id": "kerckhoffss-principle",
    "title": "Kerckhoffs's principle",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>&quot;...design your system assuming that your opponents know it in detail.&quot;</p>\n<p><em>Steven M. Bellovin&#39;s formulation of Kerckhoff&#39;s Principle</em></p>\n</blockquote>\n<p>This principle of cryptography was an axiom created by cryptographer Auguste Kerckhoffs. He stated that a cryptosystem should be secure, even if everything about the system, except the key, is public knowledge. Not to be confused with <a href=\"#todo\"><em>&quot;security through obscurity&quot;</em></a>.</p>\n<p>The gold standard for any secret-keeping system is that implementation details should be publicly distributed, without sacrificing or compromising security of said system.</p>\n<p>The history of cryptography has shown that open discussion and analysis of cryptographic systems leads to better and more secure systems - as researchers are able to test for and expose potential vulnerabilities.</p>\n<ul>\n<li><a href=\"#todo\">Shannon&#39;s Maxim</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=Kerckhoffs's+principle",
    "sourceUrl": "https://en.wikipedia.org/wiki/Kerckhoffs%27s_principle",
    "seeAlso": []
  },
  {
    "id": "the-dead-sea-effect",
    "title": "The Dead Sea Effect",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>&quot;... [T]he more talented and effective IT engineers are the ones most likely to leave - to evaporate ... [those who tend to] remain behind [are] the &#39;residue&#39; — the least talented and effective IT engineers.&quot;</p>\n<p><em>Bruce F. Webster</em></p>\n</blockquote>\n<p>The &quot;Dead Sea Effect&quot; suggests that in any organisation, the skills/talent/efficacy of engineers is often inversely proportional to their time in the company.</p>\n<p>Typically, highly skilled engineers find it easy to gain employment elsewhere and are the first to do so. Engineers who have obsolete or weak skills will tend to remain with the company, as finding employment elsewhere is difficult. This is particularly pronounced if they have gained incremental pay rises over their time in the company, as it can be challenging to get equivalent remuneration elsewhere.</p>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Dead+Sea+Effect",
    "sourceUrl": "http://brucefwebster.com/2008/04/11/the-wetware-crisis-the-dead-sea-effect/",
    "seeAlso": []
  },
  {
    "id": "the-dilbert-principle",
    "title": "The Dilbert Principle",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>Companies tend to systematically promote incompetent employees to management to get them out of the workflow.</p>\n<p><em>Scott Adams</em></p>\n</blockquote>\n<p>A management concept developed by Scott Adams (creator of the Dilbert comic strip), the Dilbert Principle is inspired by <a href=\"#the-peter-principle\">The Peter Principle</a>. Under the Dilbert Principle, employees who were never competent are promoted to management in order to limit the damage they can do. Adams first explained the principle in a 1995 Wall Street Journal article, and expanded upon it in his 1996 business book, <a href=\"#reading-list\">The Dilbert Principle</a>.</p>\n<ul>\n<li><a href=\"#the-peter-principle\">The Peter Principle</a></li>\n<li><a href=\"#putts-law\">Putt&#39;s Law</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Dilbert+Principle",
    "sourceUrl": "https://en.wikipedia.org/wiki/Dilbert_principle",
    "seeAlso": []
  },
  {
    "id": "the-pareto-principle-the-8020-rule",
    "title": "The Pareto Principle (The 80/20 Rule)",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>Most things in life are not distributed evenly.</p>\n</blockquote>\n<p>The Pareto Principle suggests that in some cases, the majority of results come from a minority of inputs:</p>\n<ul>\n<li>80% of a certain piece of software can be written in 20% of the total allocated time (conversely, the hardest 20% of the code takes 80% of the time)</li>\n<li>20% of the effort produces 80% of the result</li>\n<li>20% of the work creates 80% of the revenue</li>\n<li>20% of the bugs cause 80% of the crashes</li>\n<li>20% of the features cause 80% of the usage</li>\n</ul>\n<p>In the 1940s American-Romanian engineer Dr. Joseph Juran, who is widely credited with being the father of quality control, <a href=\"https://en.wikipedia.org/wiki/Joseph_M._Juran\">began to apply the Pareto principle to quality issues</a>.</p>\n<p>This principle is also known as: The 80/20 Rule, The Law of the Vital Few, and The Principle of Factor Sparsity.</p>\n<ul>\n<li>In 2002 Microsoft reported that by fixing the top 20% of the most-reported bugs, 80% of the related errors and crashes in windows and office would become eliminated (<a href=\"https://www.crn.com/news/security/18821726/microsofts-ceo-80-20-rule-applies-to-bugs-not-just-features.htm\">Reference</a>).</li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Pareto+Principle+(The+80%2F20+Rule)",
    "sourceUrl": "https://en.wikipedia.org/wiki/Pareto_principle",
    "seeAlso": []
  },
  {
    "id": "the-shirky-principle",
    "title": "The Shirky Principle",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>Institutions will try to preserve the problem to which they are the solution.</p>\n<p><em>Clay Shirky</em></p>\n</blockquote>\n<p>The Shirky Principle suggests that complex solutions - a company, an industry, or a technology - can become so focused on the problem that they are solving, that they can inadvertently perpetuate the problem itself. This may be deliberate (a company striving to find new nuances to a problem which justify continued development of a solution), or inadvertent (being unable or unwilling to accept or build a solution which solves the problem completely or obviates it).</p>\n<p>Related to:</p>\n<ul>\n<li>Upton Sinclair&#39;s famous line, <em>&quot;It is difficult to get a man to understand something, when his salary depends upon his not understanding it!&quot;</em></li>\n<li>Clay Christensen&#39;s <em>The Innovator&#39;s Dilemma</em></li>\n</ul>\n<ul>\n<li><a href=\"#the-pareto-principle-the-8020-rule\">Pareto Principle</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Shirky+Principle",
    "sourceUrl": "https://kk.org/thetechnium/the-shirky-prin/",
    "seeAlso": []
  },
  {
    "id": "the-peter-principle",
    "title": "The Peter Principle",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>People in a hierarchy tend to rise to their &quot;level of incompetence&quot;.</p>\n<p><em>Laurence J. Peter</em></p>\n</blockquote>\n<p>A management concept developed by Laurence J. Peter, the Peter Principle observes that people who are good at their jobs are promoted, until they reach a level where they are no longer successful (their &quot;level of incompetence&quot;). At this point, as they are more senior, they are less likely to be removed from the organisation (unless they perform spectacularly badly) and will continue to reside in a role which they have few intrinsic skills at, as their original skills which made them successful are not necessarily the skills required for their new jobs.</p>\n<p>This is of particular interest to engineers - who initially start out in deeply technical roles, but often have a career path which leads to <em>managing</em> other engineers - which requires a fundamentally different skill set.</p>\n<ul>\n<li><a href=\"#the-dilbert-principle\">The Dilbert Principle</a></li>\n<li><a href=\"#putts-law\">Putt&#39;s Law</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Peter+Principle",
    "sourceUrl": "https://en.wikipedia.org/wiki/Peter_principle",
    "seeAlso": []
  },
  {
    "id": "the-robustness-principle-postels-law",
    "title": "The Robustness Principle (Postel's Law)",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>Be conservative in what you do, be liberal in what you accept from others.</p>\n</blockquote>\n<p>Often applied in server application development, this principle states that what you send to others should be as minimal and conformant as possible, but you should aim to allow non-conformant input if it can be processed.</p>\n<p>The goal of this principle is to build systems which are robust, as they can handle poorly formed input if the intent can still be understood. However, there are potentially security implications of accepting malformed input, particularly if the processing of such input is not well tested. These implications and other issues are described by Eric Allman in <a href=\"https://queue.acm.org/detail.cfm?id=1999945\">The Robustness Principle Reconsidered</a>.</p>\n<p>Allowing non-conformant input, in time, may undermine the ability of protocols to evolve as implementors will eventually rely on this liberality to build their features.</p>\n<ul>\n<li><a href=\"#hyrums-law-the-law-of-implicit-interfaces\">Hyrum&#39;s Law</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Robustness+Principle+(Postel's+Law)",
    "sourceUrl": "https://en.wikipedia.org/wiki/Robustness_principle",
    "seeAlso": []
  },
  {
    "id": "solid",
    "title": "SOLID",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<p>This is an acronym, which refers to:</p>\n<ul>\n<li>S: <a href=\"#the-single-responsibility-principle\">The Single Responsibility Principle</a></li>\n<li>O: <a href=\"#the-openclosed-principle\">The Open/Closed Principle</a></li>\n<li>L: <a href=\"#the-liskov-substitution-principle\">The Liskov Substitution Principle</a></li>\n<li>I: <a href=\"#the-interface-segregation-principle\">The Interface Segregation Principle</a></li>\n<li>D: <a href=\"#the-dependency-inversion-principle\">The Dependency Inversion Principle</a></li>\n</ul>\n<p>These are key principles in <a href=\"#todo\">Object-Oriented Programming</a>. Design principles such as these should be able to aid developers build more maintainable systems.</p>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=SOLID",
    "sourceUrl": null,
    "seeAlso": []
  },
  {
    "id": "the-single-responsibility-principle",
    "title": "The Single Responsibility Principle",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>Every module or class should have a single responsibility only.</p>\n</blockquote>\n<p>The first of the &#39;<a href=\"#solid\">SOLID</a>&#39; principles. This principle suggests that modules or classes should do one thing and one thing only. In more practical terms, this means that a single, small change to a feature of a program should require a change in one component only. For example, changing how a password is validated for complexity should require a change in only one part of the program.</p>\n<p>Theoretically, this should make the code more robust, and easier to change. Knowing that a component being changed has a single responsibility only means that <em>testing</em> that change should be easier. Using the earlier example, changing the password complexity component should only be able to affect the features which relate to password complexity. It can be much more difficult to reason about the impact of a change to a component which has many responsibilities.</p>\n<ul>\n<li><a href=\"#todo\">Object-Oriented Programming</a></li>\n<li><a href=\"#solid\">SOLID</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Single+Responsibility+Principle",
    "sourceUrl": "https://en.wikipedia.org/wiki/Single_responsibility_principle",
    "seeAlso": []
  },
  {
    "id": "the-openclosed-principle",
    "title": "The Open/Closed Principle",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>Entities should be open for extension and closed for modification.</p>\n</blockquote>\n<p>The second of the &#39;<a href=\"#solid\">SOLID</a>&#39; principles. This principle states that entities (which could be classes, modules, functions and so on) should be able to have their behaviour <em>extended</em>, but that their <em>existing</em> behaviour should not be able to be modified.</p>\n<p>As a hypothetical example, imagine a module which is able to turn a Markdown document into HTML. Now imagine there is a new syntax added to the Markdown specification, which adds support for mathematical equations. The module should be <em>open to extension</em> to implement the new mathematics syntax. However, existing syntax implementations (like paragraphs, bullets, etc) should be <em>closed for modification</em>. They already work, we don&#39;t want people to change them.</p>\n<p>This principle has particular relevance for object-oriented programming, where we may design objects to be easily extended, but would avoid designing objects which can have their existing behaviour changed in unexpected ways.</p>\n<ul>\n<li><a href=\"#todo\">Object-Oriented Programming</a></li>\n<li><a href=\"#solid\">SOLID</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Open%2FClosed+Principle",
    "sourceUrl": "https://en.wikipedia.org/wiki/Open%E2%80%93closed_principle",
    "seeAlso": []
  },
  {
    "id": "the-liskov-substitution-principle",
    "title": "The Liskov Substitution Principle",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>It should be possible to replace a type with a subtype, without breaking the system.</p>\n</blockquote>\n<p>The third of the &#39;<a href=\"#solid\">SOLID</a>&#39; principles. This principle states that if a component relies on a type, then it should be able to use subtypes of that type, without the system failing or having to know the details of what that subtype is.</p>\n<p>As an example, imagine we have a method which reads an XML document from a structure which represents a file. If the method uses a base type &#39;file&#39;, then anything which derives from &#39;file&#39; should be usable in the function. If &#39;file&#39; supports seeking in reverse, and the XML parser uses that function, but the derived type &#39;network file&#39; fails when reverse seeking is attempted, then the &#39;network file&#39; would be violating the principle.</p>\n<p>This principle has particular relevance for object-oriented programming, where type hierarchies must be modeled carefully to avoid confusing users of a system.</p>\n<ul>\n<li><a href=\"#todo\">Object-Oriented Programming</a></li>\n<li><a href=\"#solid\">SOLID</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Liskov+Substitution+Principle",
    "sourceUrl": "https://en.wikipedia.org/wiki/Liskov_substitution_principle",
    "seeAlso": []
  },
  {
    "id": "the-interface-segregation-principle",
    "title": "The Interface Segregation Principle",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>No client should be forced to depend on methods it does not use.</p>\n</blockquote>\n<p>The fourth of the &#39;<a href=\"#solid\">SOLID</a>&#39; principles. This principle states that consumers of a component should not depend on functions of that component which it doesn&#39;t actually use.</p>\n<p>As an example, imagine we have a method which reads an XML document from a structure which represents a file. It only needs to read bytes, move forwards or move backwards in the file. If this method needs to be updated because an unrelated feature of the file structure changes (such as an update to the permissions model used to represent file security), then the principle has been invalidated. It would be better for the file to implement a &#39;seekable-stream&#39; interface, and for the XML reader to use that.</p>\n<p>This principle has particular relevance for object-oriented programming, where interfaces, hierarchies and abstract types are used to <a href=\"#todo\">minimise the coupling</a> between different components. <a href=\"#todo\">Duck typing</a> is a methodology which enforces this principle by eliminating explicit interfaces.</p>\n<ul>\n<li><a href=\"#todo\">Object-Oriented Programming</a></li>\n<li><a href=\"#solid\">SOLID</a></li>\n<li><a href=\"#todo\">Duck Typing</a></li>\n<li><a href=\"#todo\">Decoupling</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Interface+Segregation+Principle",
    "sourceUrl": "https://en.wikipedia.org/wiki/Interface_segregation_principle",
    "seeAlso": []
  },
  {
    "id": "the-dependency-inversion-principle",
    "title": "The Dependency Inversion Principle",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>High-level modules should not be dependent on low-level implementations.</p>\n</blockquote>\n<p>The fifth of the &#39;<a href=\"#solid\">SOLID</a>&#39; principles. This principle states that higher-level orchestrating components should not have to know the details of their dependencies.</p>\n<p>As an example, imagine we have a program which read metadata from a website. We would assume that the main component would have to know about a component to download the webpage content, then a component which can read the metadata. If we were to take dependency inversion into account, the main component would depend only on an abstract component which can fetch byte data, and then an abstract component which would be able to read metadata from a byte stream. The main component would not know about TCP/IP, HTTP, HTML, etc.</p>\n<p>This principle is complex, as it can seem to &#39;invert&#39; the expected dependencies of a system (hence the name). In practice, it also means that a separate orchestrating component must ensure the correct implementations of abstract types are used (e.g. in the previous example, <em>something</em> must still provide the metadata reader component a HTTP file downloader and HTML meta tag reader). This then touches on patterns such as <a href=\"#todo\">Inversion of Control</a> and <a href=\"#todo\">Dependency Injection</a>.</p>\n<ul>\n<li><a href=\"#todo\">Object-Oriented Programming</a></li>\n<li><a href=\"#solid\">SOLID</a></li>\n<li><a href=\"#todo\">Inversion of Control</a></li>\n<li><a href=\"#todo\">Dependency Injection</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Dependency+Inversion+Principle",
    "sourceUrl": "https://en.wikipedia.org/wiki/Dependency_inversion_principle",
    "seeAlso": []
  },
  {
    "id": "the-dry-principle",
    "title": "The DRY Principle",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>Every piece of knowledge must have a single, unambiguous, authoritative representation within a system.</p>\n</blockquote>\n<p>DRY is an acronym for <em>Don&#39;t Repeat Yourself</em>. This principle aims to help developers reducing the repetition of code and keep the information in a single place and was cited in 1999 by Andrew Hunt and Dave Thomas in the book <a href=\"https://en.wikipedia.org/wiki/The_Pragmatic_Programmer\">The Pragmatic Programmer</a></p>\n<blockquote>\n<p>The opposite of DRY would be <em>WET</em> (Write Everything Twice or We Enjoy Typing).</p>\n</blockquote>\n<p>In practice, if you have the same piece of information in two (or more) different places, you can use DRY to merge them into a single one and reuse it wherever you want/need.</p>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/The_Pragmatic_Programmer\">The Pragmatic Programmer</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+DRY+Principle",
    "sourceUrl": "https://en.wikipedia.org/wiki/Don%27t_repeat_yourself",
    "seeAlso": []
  },
  {
    "id": "the-kiss-principle",
    "title": "The KISS principle",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>Keep it simple, stupid</p>\n</blockquote>\n<p>The KISS principle states that most systems work best if they are kept simple rather than made complicated; therefore, simplicity should be a key goal in design, and unnecessary complexity should be avoided.  Originating in the U.S. Navy in 1960, the phrase has been associated with aircraft engineer Kelly Johnson.</p>\n<p>The principle is best exemplified by the story of Johnson handing a team of design engineers a handful of tools, with the challenge that the jet aircraft they were designing must be repairable by an average mechanic in the field under combat conditions with only these tools. Hence, the &quot;stupid&quot; refers to the relationship between the way things break and the sophistication of the tools available to repair them, not the capabilities of the engineers themselves.</p>\n<ul>\n<li><a href=\"#galls-law\">Gall&#39;s Law</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+KISS+principle",
    "sourceUrl": "https://en.wikipedia.org/wiki/KISS_principle",
    "seeAlso": []
  },
  {
    "id": "yagni",
    "title": "YAGNI",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<p>This is an acronym for <em><strong>Y</strong>ou <strong>A</strong>in&#39;t <strong>G</strong>onna <strong>N</strong>eed <strong>I</strong>t</em>.</p>\n<blockquote>\n<p>Always implement things when you actually need them, never when you just foresee that you need them.</p>\n<p>(<a href=\"https://twitter.com/RonJeffries\">Ron Jeffries</a>) (XP co-founder and author of the book &quot;Extreme Programming Installed&quot;)</p>\n</blockquote>\n<p>This <em>Extreme Programming</em> (XP) principle suggests developers should only implement functionality that is needed for the immediate requirements, and avoid attempts to predict the future by implementing functionality that might be needed later.</p>\n<p>Adhering to this principle should reduce the amount of unused code in the codebase, and avoid time and effort being wasted on functionality that brings no value.</p>\n<ul>\n<li><a href=\"#reading-list\">Reading List: Extreme Programming Installed</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=YAGNI",
    "sourceUrl": "https://en.wikipedia.org/wiki/You_ain%27t_gonna_need_it",
    "seeAlso": []
  },
  {
    "id": "the-fallacies-of-distributed-computing",
    "title": "The Fallacies of Distributed Computing",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<p>Also known as <em>Fallacies of Networked Computing</em>, the Fallacies are a list of conjectures (or beliefs) about distributed computing, which can lead to failures in software development. The assumptions are:</p>\n<ul>\n<li>The network is reliable</li>\n<li>Latency is zero</li>\n<li>Bandwidth is infinite</li>\n<li>The network is secure</li>\n<li>Topology doesn&#39;t change</li>\n<li>There is one administrator</li>\n<li>Transport cost is zero</li>\n<li>The network is homogeneous</li>\n</ul>\n<p>The first four items were listed by <a href=\"https://en.wikipedia.org/wiki/Bill_Joy\">Bill Joy</a> and <a href=\"https://twitter.com/aka_pugs\">Tom Lyon</a> around 1991 and first classified by <a href=\"https://en.wikipedia.org/wiki/James_Gosling\">James Gosling</a> as the &quot;Fallacies of Networked Computing&quot;. <a href=\"https://en.wikipedia.org/wiki/L._Peter_Deutsch\">L. Peter Deutsch</a> added the 5th, 6th and 7th fallacies. In the late 90&#39;s Gosling added the 8th fallacy.</p>\n<p>The group was inspired by what was happening at the time inside <a href=\"https://en.wikipedia.org/wiki/Sun_Microsystems\">Sun Microsystems</a>.</p>\n<p>These fallacies should be considered carefully when designing code which is resilient; assuming any of these fallacies can lead to flawed logic which fails to deal with the realities and complexities of distributed systems.</p>\n<ul>\n<li><a href=\"https://medium.com/baseds/foraging-for-the-fallacies-of-distributed-computing-part-1-1b35c3b85b53\">Foraging for the Fallacies of Distributed Computing (Part 1) - Vaidehi Joshi\n on Medium</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Fallacies+of+Distributed+Computing",
    "sourceUrl": "https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing",
    "seeAlso": []
  },
  {
    "id": "the-principle-of-least-astonishment",
    "title": "The Principle of Least Astonishment",
    "category": "Principles",
    "type": "principle",
    "icon": "💡",
    "description": "<blockquote>\n<p>People are part of the system. The design should match the user&#39;s experience, expectations, and mental models.</p>\n<p>Frans Kaashoek</p>\n</blockquote>\n<p>This principle proposes that systems and interfaces should be designed in a way that features and functionality is easily discovered and matches users expectations. Features that &#39;surprise&#39; users should be discouraged in favour of features that can be intuitively reasoned about based on existing patterns and practices.</p>\n<p>Many examples are present in user interfaces, such as a &#39;pull down&#39; gesture on a mobile appliation to refresh content. Another example would be command line tools, where many standards exist for how parameters are named, common parameters that should be available and so on.</p>\n<ul>\n<li><a href=\"#todo\">Convention Over Configuration</a></li>\n</ul>\n",
    "examples": [],
    "tags": [
      "principle"
    ],
    "imageUrl": "https://placehold.co/600x400/2c2c2c/FFA500?text=The+Principle+of+Least+Astonishment",
    "sourceUrl": "https://en.wikipedia.org/wiki/Principle_of_least_astonishment",
    "seeAlso": []
  }
]